\section{Type Inference Algorithm}
\label{sec:algorithm}

This section presents our type inference algorithm. This algorithm is
independent of the underlying pluggable typechecker: that is,
it applies equally well to any pluggable typechecker that performs flow-sensitive
local inference.

\todo{I don't like the term ``instrumented''.  It does describe what
  happened at a low level.  It does not explain what the instrumentation
  does or why it is valuable.  Maybe an ``inferring'' version of the type checker?}
\todo{The paper should explain that ``specifications'' is really ``type
  annotations'', to a first approximation.}

The key idea is to modify the underlying \emph{framework}
on which the target pluggable typecheckers are built. Pluggable
typecheckers use a modified version of the host type system
that supports type qualifiers. Our approach modifies this support
layer for pluggable typechecking in order to support inference for
any typechecker.

A typechecker $T : P \rightarrow E$
takes a program and outputs a (possibly empty) set of
type errors.  A typechecker running using our modified framework
$T' : \langle P, A \rangle \rightarrow \langle E, A' \rangle$
takes a program along with a set of type qualifiers $A$, and outputs errors and
inferences (\ie $A'$, a new set of type qualifiers).
The errors $E$ are exactly those $T$ would output, if the
type qualifiers in $A$ had been written on $P$ by a programmer.

We describe the algorithm in two parts: first,
\Cref{sec:core-algorithm} gives the fixpoint
algorithm used to infer types for a particular program
using our modified typechecking framework.
\Cref{sec:instrument} explains the modifications to the pluggable
typechecking framework that enable type inference for a pluggable
typechecker $T$ (\ie convert it to $T'$ in \cref{alg:wpi-fixpoint}).


\subsection{Fixpoint Algorithm}
\label{sec:core-algorithm}

\input{alg-wpi-fixpoint}

This section presents the core fixpoint algorithm, which appears
in \cref{alg:wpi-fixpoint}. The key idea is to iteratively analyze
the target program ($P$) with a version of the
pluggable typechecker whose core qualified type rules
have been modified to support inference in the manner described in
\cref{sec:instrument}, recording intermediate results at each
step (the sets of inferred type qualifiers $A$ and $A^{\prime}$) until
either there are no remaining typechecking errors
(\ie $E \neq \emptyset$)
or the
type qualifiers reach fixpoint (\ie $A = A^{\prime}$).

%% This fixpoint loop is quite general: its success for our
%% purposes depends heavily on the \textsc{Instrument} procedure
%% that outputs locally-inferred specifications. \Cref{sec:instrument}
%% describes how we implement \textsc{Instrument} in a way that is
%% applicable to any pluggable typechecker.

Note that this algorithm monotonically refines types---\ie
each element $a^{\prime}$ of $A^{\prime}$ is either 1) not present in $A$, or
2) there exists some element $a$ in $A$ such that $a^{\prime} \sqsubseteq a$
and both $a$ and $a^{\prime}$ qualify the same base type in the same program location.
The proof of this is by induction on the type rules in \cref{sec:instrument}.

\subsubsection{Soundness}
\label{sec:soundness}

Any inference algorithm is sound so long as the typechecker is run afterward:
even if the inference algorithm were to produce incorrect type qualifiers,
the typechecker would reject them.

\subsection{Modifications to the Typechecking Framework}
\label{sec:instrument}

The algorithm presented in \cref{sec:core-algorithm} works for
any pluggable typechecker that supports flow-sensitive inference:
that is, it does not require a type system implementer to write
any special rules to support type inference. Instead, this section
describes our approach to \emph{automatically} modify a given
pluggable typechecker to support inference, corresponding to the
\textsc{Enable\-Inference} helper function in \cref{alg:wpi-fixpoint}.

The key idea behind our inference approach to instrumenting the typechecker
is to do modify the \emph{framework}.  Once the pluggable type-checking
framework is modified, inference is enabled for every typechecker built on it.
Our modifications
can be conceptualized at the type-qualifier-theory level: that is,
we modify the rules for typechecking \emph{any} pluggable type system
so that inference is supported,
regardless of the particular qualifiers it happens to support.

Our modifications rely on the fact that practical pluggable type systems
do \emph{local}, intra-procedural flow-sensitive type inference.
This means that programmers rarely need to write annotations within method bodies.
Analogously, Java's \<var> keyword permits programmers to omit Java basetypes within
method bodies.
Programmers are more willing to write types on method
signatures, where they form valuable documentation.  (Our goal is to lift
even this burden, for type annotations)

This assumption is
reasonable in practice: programmers are generally not willing to
write type qualifiers within method bodies, and so 
the pluggable type frameworks that exist in practice \todo{all?}
support this feature~\cite{PapiACPE2008}~\todo{cite any other practical pluggable
  type frameworks that exist, if there are any}. \todo{Also mention that
  Java itself supports this now for the base type system?} \todo{Also mention
  that this seems to be a general trend in language design, citing maybe Kotlin?}

\begin{figure*}
  \begin{mathpar}
    \inferrule* [right=INVOKE]
                {
                  \std{\Gamma \vdash m(f_0,\ldots,f_n) : }~\qual{q_R}~\std{\tau_R}
                  \\
                  \std{\Gamma \vdash \forall i \in 0,\ldots,n . ~e_i :~} \qual{q_{i_A}}~\std{\tau_{i_A}}
                  \\
                  \std{\Gamma \vdash \forall i \in 0,\ldots,n . ~f_i :~} \qual{q_{i_F}}~\std{\tau_{i_F}}
                  \\
                  \std{\Gamma \vdash \forall i \in 0,\ldots,n . ~} \qual{q_{i_A}}~\std{\tau_{i_A}~\sqsubseteq}~\qual{q_{i_F}}~\std{\tau_{i_F}}
                  \\
                  \infr{\infEnv \vdash \forall i \in 0,\ldots,n . ~f_i~:~q_{i_I}~\tau_{i_F}}
                }
                {
                  \std{\Gamma \vdash m(e_0,\ldots,e_n) : }~\qual{q_R}~\std{\tau_R}
                  \\
                  \infr{\infEnv \vdash \forall i \in 0,\ldots,n . ~f_i~:~\mathit{LUB_Q}(q_{i_A},~q_{i_I})~\tau_{i_F} }
                }
                
     \inferrule* [right=NEW]
                {
                  \std{\Gamma \vdash \<new T>(f_1,\ldots,f_n) : }~\qual{q_R}~\std{\tau_R}
                  \\
                  \std{\Gamma \vdash \forall i \in 1,\ldots,n . ~e_i :~} \qual{q_{i_A}}~\std{\tau_{i_A}}
                  \\
                  \std{\Gamma \vdash \forall i \in 1,\ldots,n . ~f_i :~} \qual{q_{i_F}}~\std{\tau_{i_F}}
                  \\
                  \std{\Gamma \vdash \forall i \in 1,\ldots,n . ~} \qual{q_{i_A}}~\std{\tau_{i_A}~\sqsubseteq}~\qual{q_{i_F}}~\std{\tau_{i_F}}
                  \\
                  \infr{\infEnv \vdash \forall i \in 1,\ldots,n . ~f_i~:~q_{i_I}~\tau_{i_F}}
                }
                {
                  \std{\Gamma \vdash \<new T>(e_1,\ldots,e_n) : }~\qual{q_R}~\std{\tau_R}
                  \\
                  \infr{\infEnv \vdash \forall i \in 1,\ldots,n . ~f_i~:~\mathit{LUB_Q}(q_{i_A},~q_{i_I})~\tau_{i_F} }
                }

     \inferrule* [right=FORMAL-ASSIGN]
                {
%                  \std{f~is~a~formal~parameter} \\
                  \std{\Gamma \vdash f~:}~\qual{q_F}~\std{\tau_F} \\
                  \std{\Gamma \vdash e~:}~\qual{q_A}~\std{\tau_A} \\
                  \std{\Gamma \vdash} \qual{q_A}~\std{\tau_A~\sqsubseteq}~\qual{q_F}~\std{\tau_F} \\
                  \infr{\infEnv \vdash f~:~q_I~\tau_F}
                }
                {
                  \std{\Gamma \vdash f~:=~e} \\
                  \infr{\infEnv \vdash f~:~\mathit{LUB_Q}(q_A, q_I)~\tau_F}
                }

     \inferrule* [right=FIELD-ASSIGN]
                {
%                  \std{f~is~a~formal~parameter} \\
                  \std{\Gamma \vdash x.f~:}~\qual{q_F}~\std{\tau_F} \\
                  \std{\Gamma \vdash e~:}~\qual{q_A}~\std{\tau_A} \\
                  \std{\Gamma \vdash} \qual{q_A}~\std{\tau_A~\sqsubseteq}~\qual{q_F}~\std{\tau_F} \\
                  \infr{\infEnv \vdash C.f~:~q_I~\tau_F}
                }
                {
                  \std{\Gamma \vdash x.f~:=~e} \\
                  \infr{\infEnv \vdash C.f~:~\mathit{LUB_Q}(q_A, q_I)~\tau_F}
                }

     \inferrule* [right=RETURN]
                {
%                  \std{f~is~a~formal~parameter} \\
                  \std{\Gamma \vdash m(f_0,\ldots,f_n)~:}~\qual{q_R}~\std{\tau_R} \\
                  \std{\Gamma \vdash e~:}~\qual{q_A}~\std{\tau_A} \\
                  \std{\Gamma \vdash} \qual{q_A}~\std{\tau_A~\sqsubseteq}~\qual{q_R}~\std{\tau_R} \\
                  \infr{\infEnv \vdash m(f_0,\ldots,f_n)~:~q_I~\tau_R}
                }
                {
%                  \std{\Gamma \vdash \<return>~e} \\
                  \std{\<return>~e \in m} \\
                  \infr{\infEnv \vdash m(f_0,\ldots,f_n)~:~\mathit{LUB_Q}(q_A, q_I)~\tau_R}
                }

    \inferrule* [right=OVERRIDE]
                {
                  % return types
                  \std{\Gamma \vdash m_B(f_{0_B},\ldots,f_{n_B}) : }~\qual{q_{R_B}}~\std{\tau_{R_B}}
                  \\
                  \std{\Gamma \vdash m_P(f_{0_P},\ldots,f_{n_P}) : }~\qual{q_{R_P}}~\std{\tau_{R_P}}
                  \\
                  \std{\Gamma \vdash} \qual{q_{R_B}}~\std{\tau_{R_B}~\sqsubseteq}~\qual{q_{R_P}}~\std{\tau_{R_P}}
                  \\
                  \std{\Gamma \vdash \forall i \in 0,\ldots,n_B . ~f_{i_B} :~} \qual{q_{i_B}}~\std{\tau_{i_B}}
                  \\
                  \std{\Gamma \vdash \forall i \in 0,\ldots,n_P . ~f_{i_P} :~} \qual{q_{i_P}}~\std{\tau_{i_P}}
                  \\
                  \std{\Gamma \vdash \forall i \in 0,\ldots,n_B . ~} \qual{q_{i_B}}~\std{\tau_{i_B}~\sqsubseteq}~\qual{q_{i_P}}~\std{\tau_{i_P}}
                  \\
                  \std{\vdash n_B~=~n_P}
                  \\
                  \infr{\infEnv \vdash m_1(f_{0_B},\ldots,f_{n_B})~:~q_{R_B-I}~\tau_{R_B}}
                  \\
                  \infr{\infEnv \vdash m_P(f_{0_P},\ldots,f_{n_P})~:~q_{R_P-I}~\tau_{R_P}}
                  \\
                  \infr{\infEnv \vdash \forall i \in 0,\ldots,n_B . ~f_{i_B}~:~q_{i_B-I}~\tau_{i_B}}
                  \\
                  \infr{\infEnv \vdash \forall i \in 0,\ldots,n_P .~f_{i_P}~:~q_{i_P-I}~\tau_{i_P}}
                }
                {
                  \std{\Gamma \vdash m_B(f_{0_B},\ldots,f_{n_B})~\mathit{is~a~valid~override~of}~m_P(f_{0_P},\ldots,f_{n_P})}
                  \\
                  \infr{\infEnv \vdash m_P(f_{0_P},\ldots,f_{n_P})~:~\mathit{LUB_Q}(q_{R_B-I}, q_{R_P-I})~\tau_{R_P}}
                  \\
                  \infr{\infEnv \vdash \forall i \in 0,\ldots,n_P . ~f_{i_P}~:~\mathit{LUB_Q}(q_{i_B-I},~q_{i_P-I})~\tau_{i_P} }
                }
                
  \end{mathpar}

  \todo{These rules do not seem to handle qualifier polymorphism, where the
    return type can depend on the instantiation.  Somewhere the paper
    should discuss this, and whether our inference algorithm can handle it
    (maybe only when written by the programmer?)
    and which types of polymorphism our algorithm can handle and the
    challenges thereto.  This relevant to both \textsc{INVOKE} and \textsc{RETURN}.}

  \caption{Modified type rules used by our pluggable type framework. \std{Gray} indicates
    standard type rules for a Java-like language. \qual{Black} indicates additions to support
    pluggable typechecking. \infr{Red} indicates additions to support inference, \ie our
    contribution in this paper.
    Throughout, ``R'' subscripts refer to return types; ``F'' to formal parameters; ``A'' to
    actual arguments; and ``I'' to inference results.
    \todo{Which of the qualifier variables can be ``unqualified''?  I guess
      it is all of them?}
    In an assignment \<x=y>, \<x> is the ``formal'' and \<y> is the ``actual''.
    In the \textsc{OVERRIDE} rule, the subscripts ``B'' and ``P'' are mneumonics
    for ``suBtype'' and ``suPertype'', referring the overriding method and the overidden
    method, respectively.
    Type rules that do not require modification to support inference
    are elided for space.}
  \label{fig:type-rules}
\end{figure*}

The modified type rules appear in \cref{fig:type-rules}. \std{Gray} indicates
standard type rules for a Java-like language. \qual{Black} indicates additions to support
pluggable typechecking. \infr{Red} indicates additions to support inference, \ie our
contribution in this paper.
%
$m(f_0,\ldots,f_n)$ refers to a method declaration: $m$ is a unique method name,
and each $f_i$ refers to one of the method's formal parameter declarations. When
we write $m(f_0,\ldots,f_n) : q_R \tau_R$, we mean that $m$'s (qualified) return
type is $q_R \tau_R$. When we write $f_i : q_F \tau_F$, we mean that the declared
type of the formal parameter $f_i$ (of $m$) is $q_F \tau_F$.
%
Type rules that do not need to be modified to support inference are elided for space.
%
To read these type rules, we first need to define some terms.

$\infEnv$ is the \emph{inference environment}, similar to the standard (qualified)
typing environment $\Gamma$. $\Gamma$ maps expressions and declarations to qualified types.
$\infEnv$ maps declarations to possibly-qualified types.
$\infEnv$ only maps declarations because our inference procedure does not need to infer
types for expressions: in fact, we assume that $\Gamma$ already does so (via flow-sensitive
refinement). Rather, $\infEnv$'s purpose is to map declarations to the results of inference.
Unlike $\Gamma$, the values in $\infEnv$ are \emph{possibly-qualified}, meaning that they can either
be qualified types or unqualified types. Initially, $\infEnv$ contains qualified types only
for declarations that were qualified before the current round of inference (which may come from
the programmer or from a previous inference round in the \cref{alg:wpi-fixpoint} fixpoint loop).
Once the current round of inference terminates, $\infEnv$ is used to produce the results of the
inference round by returning the set of all qualified types: any type that remains unqualified
throughout inference is not annotated, because no information about it was learned.

A pluggable type \emph{checker} permits programmers to leave basetypes unqualified.
On APIs (class/method/field declarations), the type checker uses defaulting
rules to assign a qualifier to each unqualified basetype.
Within a code block, the type checker performs local flow-sensitive type
inference.

We define the function $\mathit{LUB_Q}(q_1, q_2)$ to account for possibly-qualified types.
$q_1$ and $q_2$ are each either a type qualifier or ``not present''.
If both arguments are qualifiers, then the result of $\mathit{LUB_Q}$
is just their least upper bound. If only one qualifier is present, then $\mathit{LUB_Q}$'s result
is that qualifier; if both qualifiers are not present, $\mathit{LUB_Q}$'s result is ``not present'',
resulting in an unqualified result.

\todo{Then, this section should describe the interesting parts of the
  modified type rules in detail? At a minimum, we should probably walk the reader through
  one of the type rules.}


\todo{Here is a fact that I think we should explain to readers.
  Within a single type-checking run, the type estimates only go up.
  Between runs (that is, in \cref{alg:wpi-fixpoint}), the type estimates
  only go down.}

\subsubsection{Completeness}
\label{sec:complete}

Note that this inference system is intentionally \emph{not} complete: it
does not and cannot infer all possibly-true type qualifiers for a given type
system. To see why not, note that type qualifiers on e.g., formal parameters
are inferred from the actual types of the arguments at call sites. If there
are no call sites for a method in a given program, then the \textsc{INVOKE}
rule will never be fired: no information will be inferred for those formal
parameters, and they will remain unqualified.

The lack of completeness is by design. Recall that our goal is not a
set of type qualifiers that perfectly captures whatever facts are true
about the program, but rather a set of type qualifiers that is useful
\emph{in practice} for typechecking programs. Not all true type qualifiers
are useful; as our experiments show, this system still produces many more
(true) type qualifiers than a human would write. \todo{Add a forward ref
  to the prior sentence.} Another benefit of completeness being a non-goal
is that our inference system is permitted to not infer a type qualifier
in practically any scenario where doing so might lead to sub-optimal results;
for example, see our handling of recursion (\cref{sec:infinite-descending-chains}).

% LocalWords:  typechecker typechecked typechecking typecheckers intra
% LocalWords:  decl standard''
