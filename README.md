This README.md file provides information about the artifact for "Inference of Resource Management Specifications." The artifact includes the implementation of our inference algorithm for both the Java and C# languages. It is provided with two separate Docker containers to facilitate easy reproduction. Each container contains the respective implementations and the case study programs used in the experiments described in Section 5 of the revise version of the paper which is uploaded in the artifact.

### Generate Inference Output

If you only want to run the scripts to view the numbers reported in the tables without actually running inference on the benchmarks, you can skip this section. Otherwise, to generate the inference output, run the following command:

```
./inference.sh
```

### Generate Numbers for Table 1
(**Note**: There are slight differences in the numbers reported by this script compared to the numbers in the original PDF we submitted for review, due to errors we fixed while preparing the artifact. The revised PDF referenced above contains the updated numbers consistent with the artifact.)

To generate the numbers for Table 1, execute the following command:

```
./table1.sh
```

**Note**: There are two discrepancies with the results presented in the paper. First, in the paper, we made a manual effort to separate @Owning annotations into three different categories: @Owning annotations on final fields, non-final fields, and params. However, by running this script, you can only observe the total count of @Owning annotations in all three categories for each benchmark. Second, in the Java implementation, the annotation referred to as @Calls in the paper is named @EnsuresCalledMethods, and the annotation referred to as @MustCall in the paper is named @InheritableMustCall.

### Generate Numbers for Table 2

Table 2 in our paper presents the number of warnings generated by the Resource Leak Checker in two scenarios: without annotations and with inferred annotations. These numbers are presented in the second and third columns of the table. The remaining columns in Table 2 involve manual analysis of the warnings and cannot be generated automatically.We provide this information separately within Zenodo, in a file named "Manual-Report.xlsx," as well as in a Google Doc [Manual-Report](https://docs.google.com/spreadsheets/d/1qEQyj2kmLOnURmDFiHAPnu-vR4NbAUIwOliGqopLqnE/edit?usp=sharing).

To reproduce Table 2, execute the

```
./table2.sh
```

### Generate Numbers for Table 3

If you are only interested in running the scripts and viewing the numbers reported in Table 3 for the verification time column, you can skip this step. However, if you would like to collect execution time by running the Resource Leak Checker on each benchmark, please execute the following command

```
./rlc-perf.sh
```

The numbers reported in the first column of Table 3.b are borrowed from the "Lightweight and Modular Resource Leak Checker" paper, as we conducted our experiments using the same module. However, to generate the numbers for columns 2 and 3 of Table 3, please execute the following command:

```
./table3.sh
```

**Note**: The numbers reported in Table 3 were generated on a machine with a 12th Gen Intel Core i-7-12700 Processor with 20 cores and 32 GB of RAM. Performance of the inference algorithm and Resource Leak Checker on the Docker container might be different compared to those reported in the paper.